{"cells":[{"metadata":{},"cell_type":"markdown","source":"Libraries Used:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport os\nprint(os.listdir(\"../input\"))\n\n# Exploratory Data Analysis Tools\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nimport matplotlib.pyplot as plt\nfrom string import ascii_letters\n\n# Modeling Tools\nimport fbprophet\nimport warnings\nimport itertools\nimport statsmodels.api as sm\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom math import sqrt\n\n\n# Data Visualization Tools\nimport seaborn as sns\nfrom matplotlib import pyplot\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.offline as offline\noffline.init_notebook_mode()\nfrom plotly import tools\nimport plotly.tools as tls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Read and Print Raw Data**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Opening source file\norg_data = pd.read_csv('../input/Monthly_data_cmo.csv')\napmc = org_data # creating a separate dataset to operate on!!\napmc.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** About the Raw Data:**"},{"metadata":{"trusted":true,"_uuid":"36498367a9d9751a1800660aed86010e4ad1bfbd"},"cell_type":"code","source":"apmc.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2d287e2c84931bfbbe2151cded0d96e1f4842bf"},"cell_type":"markdown","source":"From the description above can see that the dataset contains 3 years of data from 2014, 2015 and 2016, with 62,429 data points. However, lets check if there is any missing values."},{"metadata":{"trusted":true,"_uuid":"66e0bc42e43d4d7f03c962a051f27ab32032388d"},"cell_type":"code","source":"# Checking Missing Data points, if any\napmc = apmc.dropna(subset=['Year', 'arrivals_in_qtl', 'min_price', 'max_price', 'modal_price'])\napmc.describe() # cleaning, dropping those rows with no values in any one of the above columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"533aeeee9885834b769f79792009191493650e0b"},"cell_type":"markdown","source":"Wooah! The dataset seems to be clean in terms of No-Missing values!!"},{"metadata":{"_uuid":"9105570287280034b2907307df67c82beed33813"},"cell_type":"markdown","source":"## Exploratory Data Analysis (EDA)\n\n\n### <font color='green'>1. Total Consumption (in 3 years) v/s Commodity</font> : \n#### In order to look which commodity has sold the maximum over the years this plot is generated."},{"metadata":{"trusted":true,"_uuid":"a24ae3d52d1516c2d6d5d3e2dc07196ecd793941"},"cell_type":"code","source":"df3 = pd.DataFrame(apmc.groupby(['Commodity', 'Year']).agg('sum')).reset_index()\ndf3.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e1e7390eb1e546b8efd43e5a3d0b230641af3ae"},"cell_type":"code","source":"trace1 = go.Bar(\n    x= df3.loc[df3['Year'] == 2016].Commodity,\n    y= df3.loc[df3['Year'] == 2016].arrivals_in_qtl,\n    name='2016',\n    marker=dict(\n        color='yellow', \n        line=dict(\n            color='rgb(8,48,107)',\n            width=0.2),\n        ),\n    opacity=0.6\n)\n\ntrace2 = go.Bar(\n    x= df3.loc[df3['Year'] == 2015].Commodity,\n    y= df3.loc[df3['Year'] == 2015].arrivals_in_qtl,\n    name='2015',\n    marker=dict(\n        color='brown', \n        line=dict(\n            color='rgb(8,48,107)',\n            width=0.2),\n        ),\n    opacity=0.6\n)\n\ntrace3 = go.Bar(\n    x= df3.loc[df3['Year'] == 2014].Commodity,\n    y= df3.loc[df3['Year'] == 2014].arrivals_in_qtl,\n    name='2014',\n    marker=dict(\n        color='red', \n        line=dict(\n            color='rgb(8,48,107)',\n            width=0.2),\n        ),\n    opacity=0.6\n)\n\nlayout = go.Layout(\n    title='Commodities Purchased (in Volumes) per year'\n)\n\ndata = [trace1, trace2, trace3]\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename=\"popular_commodity\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5b9d2f114034cf4552a445c4b5e7ca9e91481e9"},"cell_type":"markdown","source":"### <font color='green'>2. Most Popular and Least Popular Commodity</font> : \n#### In order to look which commodity has sold the maximum and minimum over the years this plot is generated."},{"metadata":{"trusted":true,"_uuid":"0aaea98ddfafd8312c8f68b801246793822988ab"},"cell_type":"code","source":"df1 = pd.DataFrame(apmc.groupby(['Commodity']).sum()).reset_index()\ndf1 = df1[['Commodity', 'arrivals_in_qtl']]\n# df1.tail()\n\ndf1_a = df1[df1['arrivals_in_qtl'] > 1000000]\ndf1_a_sort = df1_a.sort_values('arrivals_in_qtl', ascending=True) # for latest python df.sort has been deprecated and updated to df.sort_values\n\n\ntrace = go.Bar(\n    x= df1_a_sort.Commodity,\n    y= df1_a_sort.arrivals_in_qtl,\n    marker=dict(\n        color='orange',\n    ),\n)\n\nlayout = go.Layout(\n    title='Most Popular Commodity'\n)\n\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename=\"popular_Commodity\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1eeb9f2a873ab0306331626f95a29944aaacbecf"},"cell_type":"markdown","source":"From the plot above we can see that the <font color='red'>Onion</font> is by far the most produced or popular Commodity in Maharashtra followed by <font color='red'>Soybean, Potato, Coriander, Cotton, Rice and Tomato</font>\n\nHowever, the onion is purchased more than 100 Million Quintals in 2 years span(Oct 2014 - Oct 2016)!!\n\nLets now check which commodities fare bad in terms of Quintals purchased. For simplification all the commodities less than 100 Quintals of purchase between (Oct 2014 - Oct 2016) is plotted"},{"metadata":{},"cell_type":"markdown","source":"**Selecting the bottom Selling Commodity in term of < 100  Quintals purchased over 2 years span**"},{"metadata":{"trusted":true,"_uuid":"2fa70e0b94389a4befbbeb06f4f36aa5efd4decb"},"cell_type":"code","source":"# selecting the bottom Selling Commodity in term of < 100  Quintals purchased over 2 years span\ndf1_b = df1[df1['arrivals_in_qtl']<100]\ndf1_b_sort = df1_b.sort_values('arrivals_in_qtl', ascending=True) # for latest python df.sort has been deprecated and updated to df.sort_values\n\ntrace = go.Bar(\n    x= df1_b_sort.Commodity,\n    y= df1_b_sort.arrivals_in_qtl,\n    marker=dict(\n        color='green',\n    ),\n)\n\nlayout = go.Layout(\n    title='Least Popular Commodity'\n)\n\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename=\"popular_Commodity\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e675a5cd68120b0fc9646784fba4c7b0b6dae4bd"},"cell_type":"markdown","source":"One interesting thing to be noted here is that all the meat products like <font color='green'> Buffalo, Sheep, Goat, skin & Bones </font> are all under 100 quintals in 2 years. This infers that there is some strict regulation In the state , in terms of purchasing meat products."},{"metadata":{"_uuid":"1b9661046a2f9a881c1480356227fccf30093c7a"},"cell_type":"markdown","source":"### <font color='green'>3. Market Share by Disctrict</font> : \n#### In order to look which district has generated the maximum market share in these two years"},{"metadata":{},"cell_type":"markdown","source":"*Feature 1:*"},{"metadata":{"trusted":true,"_uuid":"09047da7844f06828f1a45c0d4f7bdd26cf5a7c1"},"cell_type":"code","source":"#creating a new column Calculating the total market price\napmc['Total_Market_Price'] = apmc['modal_price'] * apmc['arrivals_in_qtl']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e8a3e7e3b429518d2047b3c6d0a2704b0308740"},"cell_type":"code","source":"df2 = pd.DataFrame(apmc.groupby(['district_name', 'Year']).agg('mean')).reset_index()\ndf2.tail(n=6)\n\ntrace14 = go.Bar(\n    x= df2.loc[df2['Year'] == 2014].district_name,\n    y = df2.loc[df2['Year'].isin([2014])].Total_Market_Price,\n    name='2014',\n    \n    marker=dict(\n        color='orange', \n        line=dict(\n            color='rgb(8,48,107)',\n            width=1.5),\n        ),\n    opacity=1.0\n)\n\ntrace15 = go.Bar(\n    x= df2.loc[df2['Year'] == 2015].district_name,\n    y= df2.Total_Market_Price.loc[df2['Year'] == 2015],\n    name='2015',\n    marker=dict(\n        color='purple', \n        line=dict(\n            color='rgb(8,48,107)',\n            width=1.5),\n        ),\n    opacity=0.8\n)\n\ntrace16 = go.Bar(\n    x= df2.loc[df2['Year'] == 2016].district_name,\n    y= df2.loc[df2['Year'] == 2016].Total_Market_Price,\n    name='2016',\n    marker=dict(\n        color='pink', \n        line=dict(\n            color='rgb(8,48,107)',\n            width=1.5),\n        ),\n    opacity=0.6\n)\n\nlayout = go.Layout(\n    title='Market share per district per year'\n)\n\ndata = [trace14, trace15, trace16]\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename=\"district_price\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"852ec49ffca1909d89680fb61584b75c2e6cc063"},"cell_type":"markdown","source":"<font color='red'>Mumbai </font> has the most market share for all the three years, followed by Sangli and Wardha."},{"metadata":{"_uuid":"007b1a7f880d545f0a219eacbd98e1d019158ccc"},"cell_type":"markdown","source":"### <font color='green'>4. Price versus Demand Seasonality</font> : \n#### To check the effect of seasonality in Modal Price as well as Volume purchased"},{"metadata":{"_uuid":"baddc6e13750ade31d217107bebaec22a381512a"},"cell_type":"markdown","source":" Lets sort the top 10 selling Commodities and check their seasonal variability"},{"metadata":{"trusted":true,"_uuid":"c8965a722f2e79ef46aae5fa1303939c7cac8c20"},"cell_type":"code","source":"# selecting the top 10 Selling Commodity in term of NUmber of Quintals purchased over 3 years\nprint(df1.sort_values('arrivals_in_qtl', ascending=False).head(n=10)) # for latest python df.sort has been deprecated and updated to df.sort_values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ac71e0cd044c858195ec07e00afa815485ac3c9"},"cell_type":"markdown","source":"#### Lets plot the seasonal variability of the price and quantity for these commodities"},{"metadata":{},"cell_type":"markdown","source":"*Feature 2*"},{"metadata":{"trusted":true,"_uuid":"7360f0273ea9639abf797b794b0c52c1b3f9d4b0"},"cell_type":"code","source":"df4 = apmc\ndf4 = df4.loc[df4['Commodity'].isin(['Onion','Soybean', 'Potato', 'Cotton', 'Rice(Paddy-Hus)', 'Tomato', ' Coriander  ', 'Methi (Bhaji)','Pigeon Pea (Tur)', 'Maize'])]\n# Getting the Sum and the mean of the values\ndf4_a = pd.DataFrame(df4.groupby(['Commodity', 'date']).agg('sum')).reset_index()\ndf4_b = pd.DataFrame(df4.groupby(['Commodity', 'date']).agg('mean')).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faa0a584e9627666f22ad657269c5f02c262efb5"},"cell_type":"code","source":"trace21 = go.Scatter(\n    x= df4_a.loc[df4_a['Commodity'] == 'Onion'].date,\n    y= df4_a.loc[df4_a['Commodity'] == 'Onion'].arrivals_in_qtl,\n    mode = 'lines+markers',\n    name = 'Onion'\n)\n\ntrace22 = go.Scatter(\n    x= df4_a.loc[df4_a['Commodity'] == 'Soybean'].date,\n    y= df4_a.loc[df4_a['Commodity'] == 'Soybean'].arrivals_in_qtl,\n    mode = 'lines+markers',\n    name = 'Soybean'\n)\n\ntrace23 = go.Scatter(\n    x= df4_a.loc[df4_a['Commodity'] == 'Cotton'].date,\n    y= df4_a.loc[df4_a['Commodity'] == 'Cotton'].arrivals_in_qtl,\n    mode = 'lines+markers',\n    name = 'Cotton'\n)\n\ntrace24 = go.Scatter(\n    x= df4_a.loc[df4_a['Commodity'] == 'Potato'].date,\n    y= df4_a.loc[df4_a['Commodity'] == 'Potato'].arrivals_in_qtl,\n    mode = 'lines+markers',\n    name = 'Potato'\n)\n\ntrace25 = go.Scatter(\n    x= df4_a.loc[df4_a['Commodity'] == 'Rice(Paddy-Hus)'].date,\n    y= df4_a.loc[df4_a['Commodity'] == 'Rice(Paddy-Hus)'].arrivals_in_qtl,\n    mode = 'lines+markers',\n    name = 'Rice(Paddy-Hus)'\n)\n\ntrace26 = go.Scatter(\n    x= df4_a.loc[df4_a['Commodity'] == 'Tomato'].date,\n    y= df4_a.loc[df4_a['Commodity'] == 'Tomato'].arrivals_in_qtl,\n    mode = 'lines+markers',\n    name = 'Tomato'\n)\n\ntrace27 = go.Scatter(\n    x= df4_a.loc[df4_a['Commodity'] == 'Coriander'].date,\n    y= df4_a.loc[df4_a['Commodity'] == 'Coriander'].arrivals_in_qtl,\n    mode = 'lines+markers',\n    name = 'Coriander'\n)\n\ntrace28 = go.Scatter(\n    x= df4_a.loc[df4_a['Commodity'] == 'Methi (Bhaji)'].date,\n    y= df4_a.loc[df4_a['Commodity'] == 'Methi (Bhaji)'].arrivals_in_qtl,\n    mode = 'lines+markers',\n    name = 'Methi (Bhaji)'\n)\n\ntrace29 = go.Scatter(\n    x= df4_a.loc[df4_a['Commodity'] == 'Pigeon Pea (Tur)'].date,\n    y= df4_a.loc[df4_a['Commodity'] == 'Pigeon Pea (Tur)'].arrivals_in_qtl,\n    mode = 'lines+markers',\n    name = 'Pigeon Pea (Tur)'\n)\n\ntrace20 = go.Scatter(\n    x= df4_a.loc[df4_a['Commodity'] == 'Maize'].date,\n    y= df4_a.loc[df4_a['Commodity'] == 'Maize'].arrivals_in_qtl,\n    mode = 'lines+markers',\n    name = 'Maize'\n)\n\ntrace31 = go.Bar(\n    x= df4_b.loc[df4_b['Commodity'] == 'Onion'].date,\n    y= df4_b.loc[df4_b['Commodity'] == 'Onion'].modal_price,\n    name = 'Onion_Price',\n    yaxis='y2',\n    opacity=0.5\n)\n\ntrace32 = go.Bar(\n    x= df4_b.loc[df4_b['Commodity'] == 'Soybean'].date,\n    y= df4_b.loc[df4_b['Commodity'] == 'Soybean'].modal_price,\n    name = 'Soybean_Price',\n    yaxis='y2',\n    opacity=0.5\n)\n\ntrace33 = go.Bar(\n    x= df4_b.loc[df4_b['Commodity'] == 'Cotton'].date,\n    y= df4_b.loc[df4_b['Commodity'] == 'Cotton'].modal_price,\n    name = 'Cotton_Price',\n    yaxis='y2',\n    opacity=0.5\n)\n\ntrace34 = go.Bar(\n    x= df4_b.loc[df4_b['Commodity'] == 'Potato'].date,\n    y= df4_b.loc[df4_b['Commodity'] == 'Potato'].modal_price,\n    name = 'Potato_Price',\n    yaxis='y2',\n    opacity=0.5\n)\n\ntrace35 = go.Bar(\n    x= df4_b.loc[df4_b['Commodity'] == 'Rice(Paddy-Hus)'].date,\n    y= df4_b.loc[df4_b['Commodity'] == 'Rice(Paddy-Hus)'].modal_price,\n    name = 'Rice(Paddy-Hus)_Price',\n    yaxis='y2',\n    opacity=0.5\n)\n    \ntrace36 = go.Bar(\n    x= df4_b.loc[df4_b['Commodity'] == 'Tomato'].date,\n    y= df4_b.loc[df4_b['Commodity'] == 'Tomato'].modal_price,\n    name = 'Tomato_Price',\n    yaxis='y2',\n    opacity=0.5\n)\n    \ntrace37 = go.Bar(\n    x= df4_b.loc[df4_b['Commodity'] == 'Coriander'].date,\n    y= df4_b.loc[df4_b['Commodity'] == 'Coriander'].modal_price,\n    name = 'Coriander_Price',\n    yaxis='y2',\n    opacity=0.5\n)\n    \ntrace38 = go.Bar(\n    x= df4_b.loc[df4_b['Commodity'] == 'Methi (Bhaji)'].date,\n    y= df4_b.loc[df4_b['Commodity'] == 'Methi (Bhaji)'].modal_price,\n    name = 'Methi (Bhaji)_Price',\n    yaxis='y2',\n    opacity=0.5\n)\n    \ntrace39 = go.Bar(\n    x= df4_b.loc[df4_b['Commodity'] == 'Pigeon Pea (Tur)'].date,\n    y= df4_b.loc[df4_b['Commodity'] == 'Pigeon Pea (Tur)'].modal_price,\n    name = 'Pigeon Pea (Tur)_Price',\n    opacity=0.5,\n    yaxis='y2'\n)\n    \ntrace30 = go.Bar(\n    x= df4_b.loc[df4_b['Commodity'] == 'Maize'].date,\n    y= df4_b.loc[df4_b['Commodity'] == 'Maize'].modal_price,\n    name = 'Maize_Price', \n    opacity=0.5,\n    yaxis='y2'\n)\n\n\ndata = [trace21, trace22, trace23, trace24, trace25, trace26, trace27, trace28, trace29, trace20,\n        trace31, trace32, trace33, trace34, trace35, trace36, trace37, trace38, trace39, trace30]\n    \n\nlayout = go.Layout(\n    legend=dict(orientation=\"h\"),\n    \n    title='Monthly Chart : Top 10 Commodity, Economics v/s Quantity',\n    yaxis=dict(\n        title='Quintals_Purchased_in_Maharashtra'\n    ),\n    yaxis2=dict(\n        title='Average_Modal_Price_Per_Quintal(INR)',\n        titlefont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        tickfont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        overlaying='y',\n        side='right'\n    )\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename=\"popular_commodity\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"837c4a1f1e2940dfcffae4040d789383cc7c7ffb"},"cell_type":"markdown","source":"\n\n**Instructions to access Graphs:**\n    1. Dis-select all the legend boxes by single left clicking on each one of them.\n    2. Now select Individual 'Crop' and The 'Crop_Price' by single left clicking them and compare \n\n\n\n\n<font color='blue'>Lets look into the graph:</font>\n    \n    1. Maize, Cotton, Soybean, Pigeon Pea are winter crops so their demands are higher in the winter months (NOV to FEB) -\n           There is no particular co-relation between the price and the amount purchased for both crops\n        \n    2. Methi (Bhaji) has interestingly dropped its demands in the year 2016 -\n           There is a negative co-relation between Price and Demand ( As price Increases,  Demand Decreases)\n        \n    3. Onion has seen a steep drop in demand in the month of Aug - Nov 2015 , owing to the high price increase - \n           There is a negative co-relation between Price and Demand ( As price Increases,  Demand Decreases)\n        \n    4. Potato does not show any particular seasonal trend in its demand. However, over the time the demand has increased.\n           There is a negative co-relation between Price and Demand ( As price Increases,  Demand Decreases)\n        \n    5. Rice has no particular seasonal trend. However, over the time, the demand has significantly grown.\n           There is no co-relation between the price and demand for this crop.\n        \n    6. Tomato has no seasonal Trend.\n           There is a negative co-relation between Price and Demand ( As price Increases,  Demand Decreases) "},{"metadata":{"_uuid":"eda2f645bd2fb24ffa5d6ebb514a7733480926d2"},"cell_type":"markdown","source":"### <Font color = 'Green'> 5. District Versus Least Popular Commodity </font> : \n#### This will help us identify the district which purchased least popular commodities over this period."},{"metadata":{"trusted":true,"_uuid":"816a1df962c2ee6108cddb2155d809e04e33886b"},"cell_type":"code","source":"print(df1.sort_values('arrivals_in_qtl', ascending=True).head()) # for latest python df.sort has been deprecated and updated to df.sort_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Feature 3:*"},{"metadata":{"trusted":true,"_uuid":"7ac627bff99056a0c8cf18e34b7ac2c30aee4feb"},"cell_type":"code","source":"df0 = apmc\ndf0 = df0.loc[df0['Commodity'].isin(['CASTOR SEED','LEAFY VEGETABLE', 'Baru Seed', 'Jui', 'Papnas', 'MUSTARD', \n                                           'SARSAV', 'Terda','GOATS', 'Kalvad', 'Peer', 'NOLKOL', 'Plum',\n                                          'GROUNDNUT PODS (WET)', 'Karvand', 'He Buffalo'])]\n# Getting the Sum and the mean of the values\ndf0_a = pd.DataFrame(df0.groupby(['Commodity', 'date']).agg('sum')).reset_index()\ndf0_b = pd.DataFrame(df0.groupby(['Commodity', 'date']).agg('mean')).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac840e0aba732d9a4fb554907f801b808f354830"},"cell_type":"code","source":"data = [\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'CASTOR SEED'].district_name, y=df0.loc[df0['Commodity'] == 'CASTOR SEED'].arrivals_in_qtl,\n        name = 'Castor seed', opacity=0.5),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'GOATS'].district_name, y=df0.loc[df0['Commodity'] == 'GOATS'].arrivals_in_qtl,\n        name = 'Goats', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'Karvand'].district_name, y=df0.loc[df0['Commodity'] == 'Karvand'].arrivals_in_qtl,\n        name = 'Karvand', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'He Buffalo'].district_name, y=df0.loc[df0['Commodity'] == 'He Buffalo'].arrivals_in_qtl,\n        name = 'Buffalo', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'LEAFY VEGETABLE'].district_name, y=df0.loc[df0['Commodity'] == 'LEAFY VEGETABLE'].arrivals_in_qtl,\n        name = 'Leafy Veggie', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'Baru Seed'].district_name, y=df0.loc[df0['Commodity'] == 'Baru Seed'].arrivals_in_qtl,\n        name = 'Baru Seed', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'Jui'].district_name, y=df0.loc[df0['Commodity'] == 'Jui'].arrivals_in_qtl,\n        name = 'Jui', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'Papnas'].district_name, y=df0.loc[df0['Commodity'] == 'Papnas'].arrivals_in_qtl,\n        name = 'Papnas', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'MUSTARD'].district_name, y=df0.loc[df0['Commodity'] == 'MUSTARD'].arrivals_in_qtl,\n        name = 'Mustard', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'SARSAV'].district_name, y=df0.loc[df0['Commodity'] == 'SARSAV'].arrivals_in_qtl,\n        name = 'Sarsav', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'Terda'].district_name, y=df0.loc[df0['Commodity'] == 'Terda'].arrivals_in_qtl,\n        name = 'Terda', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'Kalvad'].district_name, y=df0.loc[df0['Commodity'] == 'Kalvad'].arrivals_in_qtl,\n        name = 'Kalvad', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'Peer'].district_name, y=df0.loc[df0['Commodity'] == 'Peer'].arrivals_in_qtl,\n        name = 'Peer', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'Plum'].district_name, y=df0.loc[df0['Commodity'] == 'Plum'].arrivals_in_qtl,\n        name = 'Plum', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'NOLKOL'].district_name, y=df0.loc[df0['Commodity'] == 'NOLKOL'].arrivals_in_qtl,\n        name = 'Nolkol', opacity=0.5\n    ),\n    go.Bar(\n        x=df0.loc[df0['Commodity'] == 'GROUNDNUT PODS (WET)'].district_name, y=df0.loc[df0['Commodity'] == 'GROUNDNUT PODS (WET)'].arrivals_in_qtl,\n        name = 'Groundnut Pods', opacity=0.5\n    )\n\n]\n\n\nlayout = go.Layout(\n    barmode='stack',\n    title='Least Popular Commodities and their Purchase District',\n    yaxis=dict(\n        title='Quintals_Purchased'\n    )\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename=\"popular_commodity\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73a3f693291204e7833b84d65501c2f81e49ffbf"},"cell_type":"markdown","source":"Here, we can see that 'Pune' has the maximum number of 'Least Popular' commodities <Font Color = 'Blue'> (Less than 10 Quintals) </Font> being purchased. Interestingly, Mumbai,Wardha, Sangli which has the top 3 market share does not surface in this list at all!"},{"metadata":{"_uuid":"e9cee9e95525d0e29da832994cf75e67d66e3aba"},"cell_type":"markdown","source":"### <Font Color ='Green'> 6. Price range of a Commodity V/S Districts </Font> : \n#### To Identify the districts with highest and lowest price ranges for a particular Commodity"},{"metadata":{},"cell_type":"markdown","source":"*Feature 4:*"},{"metadata":{"trusted":true,"_uuid":"553046f1690ab7b21949fc7463c947adc773d638"},"cell_type":"code","source":"df6 = apmc\ndf6_a = pd.DataFrame(df6.groupby(['Commodity', 'district_name']).agg('mean')).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"398dbb2fb9c0aebd08ddaf63324ac10831bd427b"},"cell_type":"code","source":"Commodity = 'Maize'\n\ntrace00 = go.Scatter(\n    x= df6_a.loc[df6_a['Commodity'] == Commodity].district_name,\n    y= df6_a.loc[df6_a['Commodity'] == Commodity].max_price,\n    mode = 'lines+markers',\n    line = dict(\n        color = ('rgb(22, 96, 167)'),\n        width = 2,\n        dash = 'dot'),\n    name = 'Price_MAX', \n    opacity=0.5\n)\n\ntrace01 = go.Scatter(\n    x= df6_a.loc[df6_a['Commodity'] == Commodity].district_name,\n    y= df6_a.loc[df6_a['Commodity'] == Commodity].modal_price,\n    mode = 'lines+markers',\n    line = dict(\n        color = ('Red'),\n        width = 2),\n    name = 'Price_MODE',\n    opacity=1.0\n)\n\ntrace02 = go.Scatter(\n    x= df6_a.loc[df6_a['Commodity'] == Commodity].district_name,\n    y= df6_a.loc[df6_a['Commodity'] == Commodity].min_price,\n    mode = 'lines+markers',\n    line = dict(\n        color = ('rgb(22, 96, 167)'),\n        width = 2,\n        dash = 'dot'),\n    name = 'Price_MIN', \n    opacity=0.5\n)\n\ntrace03 = go.Bar(\n    x= df6_a.loc[df6_a['Commodity'] == Commodity].district_name,\n    y= df6_a.loc[df6_a['Commodity'] == Commodity].arrivals_in_qtl,\n    name = 'Quantity', \n    opacity=0.2,\n    yaxis='y2'\n)\n\n\ndata = [trace00, trace01, trace02, trace03]\n\n    \n\nlayout = go.Layout(\n    legend=dict(orientation=\"v\"),\n    \n    title='Price Range Chart district-wise',\n    yaxis=dict(\n        title='Price per Quintal'\n    ),\n    yaxis2=dict(\n        title='Average_Quintal',\n        titlefont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        tickfont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        overlaying='y',\n        side='right'\n    )\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename=\"popular_commodity\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2c1b8dc2bac569c85a8d33152e351223336c673"},"cell_type":"markdown","source":"<font color='blue'>\n**Instructions to access Graphs:**</font>\n<br>\n<font color='blue'>    \n    1. In the commodity Section type any Commodity name as per your choice (by default it is Onion)</font>\n<font color='blue'>     \n    2. Run the code snippet </font>\n\n<br>\n\n*Lets look into the graph:*\n    \n   1. For Onion (The most widely sold product, there is inconsistency in average prices across the districts. Onions are heavily costly in <Font Color = 'Red'> Jalna </font>.\n   \n   2. For Maize the cheapest price available is in <Font Color = 'Red'> Wasim </font>.\n   \n           \n           \nHowever, for all the commodities , there is no particular co-relation between the price each district and the demand. (It might be more clear if the economics is broken down, but the data is not available for that)\n    "},{"metadata":{"_uuid":"1260541897b03d6558194af9e6aadc7d46cc4ef5"},"cell_type":"markdown","source":"### <font color='green'>7. Co-relation Check </font> : \n#### To check if any of the attributes are heavily corelated with other : \n\n##### a. for Most popular Commodities (top 5) \n##### b. for Least popular Commodities (bottom 10)"},{"metadata":{"trusted":true,"_uuid":"23a6cbaf4ac689ea50a39214920b217f9dcd5f91"},"cell_type":"code","source":"df7 = apmc\ndf7_a = df7.loc[df7['Commodity'].isin(['CASTOR SEED','LEAFY VEGETABLE', 'Baru Seed', 'Jui', 'Papnas', 'MUSTARD', \n                                           'SARSAV', 'Terda','GOATS', 'Kalvad', 'Peer', 'NOLKOL', 'Plum',\n                                          'GROUNDNUT PODS (WET)', 'Karvand', 'He Buffalo'])]\n\ndf7_a= df7_a[[ 'Year', 'date' , 'arrivals_in_qtl', 'modal_price', 'min_price', 'max_price', 'Total_Market_Price' ]]\n\nsns.set(style=\"white\")\n\n# Generate a large random dataset\nd = df7_a\n\n# Compute the correlation matrix\ncorr = d.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91013b15a86a7ff0efbf1aa40b91806a3ec2f317"},"cell_type":"code","source":"df7_b = df7.loc[df7['Commodity'].isin(['Onion', 'Soybean','Potato', 'Cotton', 'Rice(Paddy-Hus)'])]\n\ndf7_b= df7_b[[ 'Year', 'date' , 'arrivals_in_qtl', 'modal_price', 'min_price', 'max_price', 'Total_Market_Price' ]]\n\nsns.set(style=\"white\")\n\n# Generate a large random dataset\nd = df7_b\n\n# Compute the correlation matrix\ncorr = d.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"207e6e2ad81117dc55e5e58ab49c192ebe4fcc86"},"cell_type":"markdown","source":"#### Note:\n\nComparing the second Image from the first one we can see that there is a striking difference in co-relation between \n Quantity and Modal Prices. \n \nFor Top Performimng Commodities these fators are weakly corelated. Which is not the same case for least purchased commodities.\n \nIs it because there are very less datapoints or scattered datapoints for the former?? (May be!!)"},{"metadata":{"_uuid":"d0651181fe5ad6a41c2100ebd182ea046c675967"},"cell_type":"markdown","source":"### <font color='green'>8. District versus total market price(Monthly Pattern) </font> : \n#### To identify if there is any monthly pattren of total market price distribution for the top performing districts ."},{"metadata":{"trusted":true,"_uuid":"bf1bb09fd5791f98951cef3e7081d32879d8a684"},"cell_type":"code","source":"df8 = apmc\ndf8 = df8.loc[df8['district_name'].isin(['Mumbai','Sangli', 'Wardha', 'Pune', 'Thane', 'Wasim', 'Nasik','Yewatmal', 'Gondiya'])]\ndf8_a = pd.DataFrame(df8.groupby(['district_name', 'Month']).agg('mean')).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10f28db7752b54c0cadaea81b4eede75f8a9e5fb"},"cell_type":"code","source":"a4_dims = (15, 8.27)\nfig, ax = pyplot.subplots(figsize=a4_dims)\n\n# sns.set(style=\"whitegrid\")\np = sns.violinplot(ax = ax,\n                   data=df8_a,\n                   x = 'district_name',\n                   y = 'Total_Market_Price', bw=0.5, saturation = 1.25, width = 1.1\n                   )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fad097903e02313dfc09268fe5b12d0e606be532"},"cell_type":"markdown","source":"#### Note:\nFrom the above graph we can say that the average market price over the months from top performing districts :\n\n1. Nasik, Pune, Thane have high seasonal market cap.\n2. Wasim has the mean price of the commodities on higher band in most of the months.\n3. Yewatmal, Gondiya  has the mean price of the commodities on lower band in most of the months.\n4. Mumbai, Sangli and Wardha has their mean market price evenly distributed across the months."},{"metadata":{"_uuid":"138fc1b9c835810c0301ab25ce18a207d8851eb8"},"cell_type":"markdown","source":"# Price Forecasting Model\n\n\n---------------------------\n\n\n<font color = 'Blue'> Two Forecast models have been created:</font>\n\n1. AR-I-MA    : Based on regression and moving average \n\n2. FbProphet  : Based on Bayesian fourier series \n\n---------------------------\n\n<font color = 'Blue'>In order to forecast the price of an item 3 month ahead, following steps has been performed:</font>\n\n<font color = 'red'>Step 1:</font> Curate the dataset \n<font color = 'red'>Step 2:</font> Up-Sample the dataset\n<font color = 'red'>Step 3:</font> Check for Stationarity\n<font color = 'red'>Step 4:</font> Check for trend\n<font color = 'red'>Step 5:</font> Use modeling equations\n"},{"metadata":{"_uuid":"3f6f78c95e7d2c3ffac52251c063ec60b04efef3"},"cell_type":"markdown","source":"###  <Font color = 'red' >ARIMA Forecasting Model </font>"},{"metadata":{"_uuid":"cd62ea8b0704ca3f07ec805aa04154465460cb14"},"cell_type":"markdown","source":"Auto Regression- Integrated- Moving Average is a model that incorporates future, past and seasonal variability of a data in modeling the forecasted value of a dataset,\n\nARIMA is a commomnly used timeseries forecast model in the industry today and is approached due to its robustness in terms of detecting seasonality."},{"metadata":{},"cell_type":"markdown","source":"** Curating Dataset according to the model checks and needs:**\n\n> --> For our testing purpose Pigeon Pea has been selected as our test case."},{"metadata":{"trusted":true,"_uuid":"e488fcab0db7b976d40d8dfa0f9f356595b66a24"},"cell_type":"code","source":"df5 = apmc\ndf5 = df5.loc[df5['Commodity'].isin(['Pigeon Pea (Tur)'])]\ndf5 = pd.DataFrame(df5.groupby(['date']).agg('mean')).reset_index()\ndf5 = df5 [['date', 'modal_price']]\ndf5.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting the basic price variability with monthly data**"},{"metadata":{"trusted":true,"_uuid":"dac85509094868f851c3a98de9b49dddfd250eaf"},"cell_type":"code","source":"\ntrace00 = go.Scatter(\n    x= df5.date,\n    y= df5.modal_price,\n    mode = 'lines+markers',\n)\n\nlayout = go.Layout(\n    title='Pigeon_Pea Prices across the month'\n)\n\ndata = [trace00]\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename=\"popular_commodity\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37ee0227827a57385d70bd5d47cd4023c9f2b12a"},"cell_type":"markdown","source":"<font color = 'blue'> Here we can see that the commodity price has increased over the period and then decreased recently. However, overall there has been some growth. </Font>\n\nBefore we move into forecasting lets check the seasonality of this data. "},{"metadata":{"trusted":true,"_uuid":"3623d469cda555a93fde679d906ecd95976999bb"},"cell_type":"code","source":"#Preparing the dataset:   \n\ndf5.to_csv('forecast_APMC.csv')\n# df5.dtypes # our datatypes for date column is in objects, we shall convert it to datetime \ndateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m')\n\ndf5 = pd.read_csv('forecast_APMC.csv', parse_dates=['date'], index_col='date',date_parser=dateparse) # indexed the date column\ndf5 = df5[['modal_price']]\ndf5.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"622dd73c58af37d2a7c3e368fb9e0bafa92e2b09"},"cell_type":"markdown","source":"#### UP Sampling\n\n\n\n<font color = 'Blue'> Need to upsample to weekly data from monthly since we have only 26 datapoints and we need atleast 100 points to perform ARIMA forecast </font>"},{"metadata":{"trusted":true,"_uuid":"e0a9d660853bd2cb4eca03afb6d6a0143f9b1cd5"},"cell_type":"code","source":"ts = df5\nticks = ts.loc[:, ['modal_price']]\nupsampled = ticks.modal_price.resample('7D', how = 'last') # upsampling it to weekly data points\ninterpolated = upsampled.interpolate(method='spline', order=2) # for more smoothened curve values. \n# print(interpolated )\nplt.plot(interpolated, color='red', label = 'Interpolated weekly data')\nplt.plot(ts, color='green', label = 'Original Monthly data')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"178ac69dbf44b1e047fb8124928b1505b4d1c31e"},"cell_type":"markdown","source":"From the graph above, the <font color = 'green'> green </font> line plot is the original monthly data and the <font color = 'red'> red </font> line is the upsampled weekly data plot. \n\nThe weekly data (red line) is more smoother as there are more number of interpolated data points. Now we have the number of data points = 113"},{"metadata":{"_uuid":"9b06c75467bce013fc2e619b0bc00a5bf39c886f"},"cell_type":"markdown","source":"### 1. ARIMA Forecast Model"},{"metadata":{},"cell_type":"markdown","source":"*Test-Train Split*"},{"metadata":{"trusted":true,"_uuid":"e1c5fee0c9f9b6be345fefa99bb22bfdf89bcb66"},"cell_type":"code","source":"# split into train and test sets\n \nstart_train = 0          # add variable integer for location of data points for start of training\nend_train = 100          # add variable integer for location of data points for end of training\nstart_test = 100        # add variable integer for location of data points for start of testing\nend_test = 112          # add variable integer for location of data points for end of testing\n\nX = interpolated\n\ntrain, test = X[start_train:end_train], X[start_test:end_test]\n# train, test = train_test_split(interpolated, test_size=0.2)       # splitting into train and test\nhistory = [interpolated for interpolated in train]                  # creating a historical memory bin\npredictions_forecast = list()                                    # creating an empty list for prediction forecasts\npredictions_CI = list()                                          # creating an empty list for 95% Confidence Intervals\npredictions_STD = list()  \n\ntest = test.tolist()    # converting test to list...\ntrain_list = train.tolist()  # converting train to list...","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Forecast*"},{"metadata":{"trusted":true,"_uuid":"b51ffa13fa1168721b4eb64ae0ee72a31f0df97a"},"cell_type":"code","source":"# walk-forward validation\nfor t in range(len(test)):\n\t# fit model\n\tmodel = ARIMA(history, order=(2,1,2)) # ideal order is taken from the AIC test above\n\tmodel_fit = model.fit()\n\n# one step forecast\n# \tyhat = model_fit.forecast()[0]\n\tforecast, stderr, conf = model_fit.forecast(steps = 1, alpha = 0.05) \n\n# store forecast and ob\n\tpredictions_forecast.append(forecast)\n\tpredictions_STD.append(stderr)\n\tpredictions_CI.append(conf)\n\thistory.append(test[t])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot Residual Error**"},{"metadata":{"trusted":true,"_uuid":"4625d8cd026819e24d306f962ffeca2a4e50417f"},"cell_type":"code","source":"residual_error = [predictions_forecast-test for predictions_forecast,test in zip(predictions_forecast,test)]\nplt.plot(residual_error, color='orange', label='Residual Errors')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9579330d5449120967bc9e3f48a1dbba414768f"},"cell_type":"markdown","source":"##### Note:\n\nWe can see that the residual error is mostly positive indicating that the model has over predicted most of the times, although by a small margin."},{"metadata":{},"cell_type":"markdown","source":"**Forecasted versus Original Data Plot**"},{"metadata":{"trusted":true,"_uuid":"80ad020d985fe6d858b152a515e9d531364808ac"},"cell_type":"code","source":"# plot forecasts against actual outcomes\nplt.figure(figsize=(8,4))\nplt.plot(test, color = 'blue', label = 'Test Data')\nplt.plot(predictions_forecast, color='red' , label='Predicted Data')\n\nplt.grid(True)\nplt.xticks(rotation=90)\nplt.xlabel(\"Units\")\nplt.ylabel(\"Power Demand (kW)\")\n# plt.ylim(ymin=0)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e55b7f5cf8aef596cb63fdaa417155bfe40902d"},"cell_type":"markdown","source":"------------------------------"},{"metadata":{"_uuid":"d18c48c2657e0b3de4427cf637a1d7f0cd93b343"},"cell_type":"markdown","source":"### 2. FbProphet Model"},{"metadata":{"trusted":true,"_uuid":"507c17563bc08a9d3f7fd19e1e7509fd03bc7b1a"},"cell_type":"code","source":"# data curating\nprophet_data = pd.read_csv('forecast_APMC.csv', parse_dates=['date'], index_col='date', date_parser=dateparse)\nprophet_data =  prophet_data[[ 'modal_price']]\n# prophet_data.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Curated and upsampled Data**"},{"metadata":{"trusted":true,"_uuid":"7455b1adf36981f7f6f02a647386f9aab3e106e9"},"cell_type":"code","source":"#UPSAMPLING\nticks = prophet_data.loc[:, ['modal_price']]\nupsampled = ticks.modal_price.resample('D', how = 'last') # upsampling it to daily data points\ndata = upsampled.interpolate(method='spline', order=2) # for more smoothened curve values. \n# print(interpolated )\ndata.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc7932e09ca5ed15ac4d14b35b416a2e4c54aa77"},"cell_type":"code","source":"data=data.reset_index()\ndata = data[['date', 'modal_price']]\ndata.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49f0da2816a10f804721908aacfaad4a127bae3f"},"cell_type":"code","source":"# Prophet requires columns ds (Date) and y (value)\nprc = data.rename(columns={'date': 'ds', 'modal_price': 'y'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Model Fitting*"},{"metadata":{"trusted":true,"_uuid":"c8039143d95a9d5653b8c1b349ba881bd57fe1c1"},"cell_type":"code","source":"# Make the prophet model and fit on the data\nprc_prophet = fbprophet.Prophet(changepoint_prior_scale=0.90, seasonality_prior_scale = 0.99) # keeping High sensitivity to seasonal variability and changing points\nprc_prophet.fit(prc) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Forecasting Model*"},{"metadata":{"trusted":true,"_uuid":"baf7bbf58df1fc91195421d2d884ff496f67b296"},"cell_type":"code","source":"# Make a future dataframe for next 90 days (3 months)\nprc_forecast = prc_prophet.make_future_dataframe(periods=90, freq= \"d\") \n# Make predictions\nprc_forecast = prc_prophet.predict(prc_forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"191dcdf0e5ebd547ffa28fdcb5664a6e6eee7db8"},"cell_type":"code","source":"prc_forecast = prc_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(n=90) \nprc_forecast.tail()\n\n# yhat --> forecasted Modal Price\n# yhat_lower and yhat_upper --> forecasted 95% confidence interval range of modal price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8d87af26bec56c7d136724eca93f1fadd3a0b69"},"cell_type":"code","source":"prc_prophet.plot(prc_forecast, xlabel = 'Date', ylabel = 'Commodity_Price')\nplt.ylim(ymin=0);\nplt.title('Price Predictions');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"068e8bf58953dc1b4fc6d04f9388107a8359342d"},"cell_type":"markdown","source":"##### Note:\n\nFrom this model we can get the upper and lower bound rages. However, it is to be seen that the 95% confidence interval becomes weak exponentially as the number of days increases."},{"metadata":{"trusted":true,"_uuid":"ca3e2851b710ce7eef1eb5ab4a22ba2ec4c694f5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}